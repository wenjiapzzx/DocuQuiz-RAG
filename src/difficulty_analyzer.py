"""
éš¾åº¦åˆ†ææ¨¡å—
è´Ÿè´£åˆ†æç”Ÿæˆé¢˜ç›®çš„éš¾åº¦ç­‰çº§
"""
import re
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple
from difflib import SequenceMatcher
from sentence_transformers import SentenceTransformer


class QuestionDifficultyAnalyzer:
    """é¢˜ç›®éš¾åº¦åˆ†æå™¨"""
    
    def __init__(self, model_name: str = "BAAI/bge-m3"):
        """
        åˆå§‹åŒ–éš¾åº¦åˆ†æå™¨
        
        Args:
            model_name: ç”¨äºè¯­ä¹‰åˆ†æçš„æ¨¡å‹åç§°
        """
        # åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
        self.model = SentenceTransformer(model_name)
        
        # å®šä¹‰éš¾åº¦ç­‰çº§
        self.difficulty_levels = {
            0: "ğŸŸ¢ ç®€å•(1æ˜Ÿ)",
            1: "ğŸŸ¡ åŸºç¡€(2æ˜Ÿ)", 
            2: "ğŸŸ  ä¸­ç­‰(3æ˜Ÿ)",
            3: "ğŸ”´ å›°éš¾(4æ˜Ÿ)",
            4: "â­ æŒ‘æˆ˜(5æ˜Ÿ)"
        }
        
        # é€šä¿¡ä¸“ä¸šæœ¯è¯­åˆ—è¡¨
        self.technical_terms = [
            'MIMO',  # å¤šè¾“å…¥å¤šè¾“å‡º
            'CSI',   # ä¿¡é“çŠ¶æ€ä¿¡æ¯
            'SNR',   # ä¿¡å™ªæ¯”
            'ä¿¡æº',  # ä¿¡æ¯æº
            'ä¿¡é“',  # é€šä¿¡ä¿¡é“
            'ç¼–ç ',  # ç¼–ç 
            'è§£ç ',  # è§£ç 
            'è¯­ä¹‰',  # è¯­ä¹‰
            'OFDM',  # æ­£äº¤é¢‘åˆ†å¤ç”¨
            'QAM',   # æ­£äº¤å¹…åº¦è°ƒåˆ¶
            'æ³¢æŸæˆå½¢',  # Beamforming
            'NOMA',  # éæ­£äº¤å¤šå€æ¥å…¥
            'FEC',   # å‰å‘çº é”™
            'æ¯«ç±³æ³¢',  # mmWave
            'URLLC', # è¶…é«˜å¯é ä½æ—¶å»¶é€šä¿¡
            'ç½‘ç»œåˆ‡ç‰‡',  # Network Slicing
            'æåŒ–ç ',  # Polar Codes
            'å¹²æ‰°å¯¹é½',  # Interference Alignment
            'è¾¹ç¼˜è®¡ç®—',  # Edge Computing
            'C-RAN',  # äº‘æ— çº¿æ¥å…¥ç½‘
            'å¤šå¾„è¡°è½',  # Multipath Fading
            'é¢‘è°±å…±äº«',  # Spectrum Sharing
        ]
    
    def extract_options(self, question_text: str) -> List[str]:
        """
        æå–é¢˜ç›®ä¸­çš„é€‰é¡¹ä¿¡æ¯
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            
        Returns:
            é€‰é¡¹æ–‡æœ¬åˆ—è¡¨
        """
        options = []
        lines = question_text.split('\n')
        
        for line in lines:
            # æŸ¥æ‰¾å½¢å¦‚ "- A." "- B." ç­‰çš„é€‰é¡¹è¡Œ
            stripped_line = line.strip()
            if stripped_line.startswith('- ') and '. ' in stripped_line:
                option = stripped_line[2:]  # å»æ‰"- "å‰ç¼€
                if len(option) >= 2 and option[0].isalpha() and option[1] == '.':
                    option_text = option[2:].strip()
                    if option_text:
                        options.append(option_text)
        
        return options
    
    def calculate_option_similarity(self, options: List[str]) -> float:
        """
        è®¡ç®—é€‰é¡¹ä¹‹é—´çš„ç›¸ä¼¼åº¦
        
        Args:
            options: é€‰é¡¹åˆ—è¡¨
            
        Returns:
            å¹³å‡ç›¸ä¼¼åº¦
        """
        if not options or len(options) < 2:
            return 0.0
        
        total_similarity = 0.0
        comparisons = 0
        
        # è®¡ç®—æ‰€æœ‰é€‰é¡¹å¯¹ä¹‹é—´çš„ç›¸ä¼¼åº¦
        for i in range(len(options)):
            for j in range(i + 1, len(options)):
                similarity = SequenceMatcher(None, options[i], options[j]).ratio()
                total_similarity += similarity
                comparisons += 1
        
        # è¿”å›å¹³å‡ç›¸ä¼¼åº¦
        return total_similarity / comparisons if comparisons > 0 else 0.0
    
    def analyze_complexity_features(self, question_text: str) -> Tuple[float, float]:
        """
        åˆ†æé¢˜ç›®å¤æ‚åº¦ç‰¹å¾
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            
        Returns:
            (é•¿åº¦åˆ†æ•°, æœ¯è¯­åˆ†æ•°) çš„å…ƒç»„
        """
        # è®¡ç®—é¢˜ç›®é•¿åº¦åˆ†æ•° (å½’ä¸€åŒ–)
        length_score = min(len(question_text) / 1000, 1.0)
        
        # æ£€æµ‹ä¸“ä¸šæœ¯è¯­æ•°é‡
        term_count = sum(1 for term in self.technical_terms if term in question_text)
        term_score = min(term_count / 10, 1.0)  # å½’ä¸€åŒ–æœ¯è¯­åˆ†æ•°
        
        return length_score, term_score
    
    def get_difficulty_level(self, similarity_score: float, length_score: float, term_score: float) -> str:
        """
        ç¡®å®šéš¾åº¦ç­‰çº§(1-5æ˜Ÿ)
        
        Args:
            similarity_score: ç›¸ä¼¼åº¦å¾—åˆ† (0-1ï¼Œç›¸ä¼¼åº¦è¶Šä½éš¾åº¦è¶Šé«˜)
            length_score: é•¿åº¦å¾—åˆ† (0-1)
            term_score: æœ¯è¯­å¾—åˆ† (0-1)
        
        Returns:
            éš¾åº¦ç­‰çº§æè¿°
        """
        # ç»¼åˆè¯„åˆ† (ç›¸ä¼¼åº¦è¶Šä½éš¾åº¦è¶Šé«˜)
        total_score = (1 - similarity_score) * 0.5 + length_score * 0.2 + term_score * 0.3
        
        # è®¾å®šæ˜ç¡®çš„åˆ†æ•°åŒºé—´å¯¹åº”1-5æ˜Ÿ
        if total_score < 0.2:
            return self.difficulty_levels[0]  # 1æ˜Ÿ - éå¸¸ç®€å•
        elif total_score < 0.4:
            return self.difficulty_levels[1]  # 2æ˜Ÿ - ç®€å•
        elif total_score < 0.6:
            return self.difficulty_levels[2]  # 3æ˜Ÿ - ä¸­ç­‰
        elif total_score < 0.8:
            return self.difficulty_levels[3]  # 4æ˜Ÿ - å›°éš¾
        else:
            return self.difficulty_levels[4]  # 5æ˜Ÿ - éå¸¸å›°éš¾
    
    def analyze_question(self, question_text: str) -> Dict[str, any]:
        """
        åˆ†æå•ä¸ªé¢˜ç›®çš„éš¾åº¦
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            
        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        # æå–é€‰é¡¹
        options = self.extract_options(question_text)
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        similarity_score = self.calculate_option_similarity(options)
        length_score, term_score = self.analyze_complexity_features(question_text)
        
        # ç¡®å®šéš¾åº¦ç­‰çº§
        difficulty = self.get_difficulty_level(similarity_score, length_score, term_score)
        
        analysis = {
            "é€‰é¡¹æ•°é‡": len(options),
            "é€‰é¡¹ç›¸ä¼¼åº¦": f"{similarity_score:.3f}",
            "é¢˜ç›®é•¿åº¦å¾—åˆ†": f"{length_score:.3f}",
            "ä¸“ä¸šæœ¯è¯­å¾—åˆ†": f"{term_score:.3f}",
            "éš¾åº¦ç­‰çº§": difficulty,
            "ç»¼åˆå¾—åˆ†": f"{(1 - similarity_score) * 0.5 + length_score * 0.2 + term_score * 0.3:.3f}"
        }
        
        return analysis
    
    def format_question(self, question_text: str) -> str:
        """
        æ ¼å¼åŒ–é¢˜ç›®æ–‡æœ¬ï¼ŒåŒ…å«é€‰é¡¹
        
        Args:
            question_text: åŸå§‹é¢˜ç›®æ–‡æœ¬
            
        Returns:
            æ ¼å¼åŒ–åçš„é¢˜ç›®æ–‡æœ¬
        """
        lines = question_text.strip().split('\n')
        question = lines[0].strip()
        options = [line.strip() for line in lines if line.strip().startswith('- ')]
        return question + '\n' + '\n'.join(options)
    
    def analyze_file_and_update(self, markdown_file: str, output_file: str = None) -> None:
        """
        åˆ†ææ–‡ä»¶ä¸­çš„æ‰€æœ‰é¢˜ç›®å¹¶æ›´æ–°éš¾åº¦ç­‰çº§
        
        Args:
            markdown_file: è¾“å…¥çš„markdownæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¦†ç›–åŸæ–‡ä»¶
        """
        # è¯»å–åŸå§‹æ–‡ä»¶
        content = Path(markdown_file).read_text(encoding='utf-8')
        
        # æå–æ‰€æœ‰é¢˜ç›®å—
        sections = re.split(r'\n(\d+\. \[é€‰æ‹©é¢˜\])', content)
        new_content = sections[0]  # ä¿ç•™æ–‡ä»¶å¼€å¤´
        
        # å¤„ç†æ¯ä¸ªé¢˜ç›®
        i = 1
        while i < len(sections):
            if i + 1 < len(sections):
                # è·å–é¢˜ç›®ç¼–å·å’Œé¢˜ç›®å†…å®¹
                question_header = sections[i]
                question_block = sections[i + 1]
                
                # æ ¼å¼åŒ–é¢˜ç›®æ–‡æœ¬
                question_text = self.format_question(question_header + question_block)
                
                # åˆ†æé¢˜ç›®éš¾åº¦
                analysis = self.analyze_question(question_text)
                print(f"é¢˜ç›®åˆ†æ {analysis}")
                
                # åœ¨é¢˜ç›®ç¼–å·åæ·»åŠ éš¾åº¦ç­‰çº§
                updated_header = question_header.replace(
                    "[é€‰æ‹©é¢˜]", 
                    f"[é€‰æ‹©é¢˜] {analysis['éš¾åº¦ç­‰çº§']}"
                )
                
                new_content += updated_header + question_block
                i += 2
            else:
                new_content += sections[i]
                i += 1
        
        # å†™å…¥æ–‡ä»¶
        if output_file is None:
            output_file = markdown_file
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"éš¾åº¦åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {output_file}")
    
    def generate_difficulty_report(self, markdown_file: str, output_file: str = None) -> Dict[str, any]:
        """
        ç”Ÿæˆéš¾åº¦åˆ†ææŠ¥å‘Š
        
        Args:
            markdown_file: markdownæ–‡ä»¶è·¯å¾„
            output_file: æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        # è¯»å–æ–‡ä»¶å¹¶æå–é¢˜ç›®
        content = Path(markdown_file).read_text(encoding='utf-8')
        question_blocks = re.findall(r'\d+\. \[é€‰æ‹©é¢˜\](.*?)(?=\n\d+\. \[é€‰æ‹©é¢˜\]|\Z)', content, re.DOTALL)
        
        # åˆ†ææ¯é“é¢˜ç›®
        analyses = []
        difficulty_distribution = {level: 0 for level in self.difficulty_levels.values()}
        
        for i, block in enumerate(question_blocks, 1):
            question_text = self.format_question(block)
            analysis = self.analyze_question(question_text)
            analyses.append({
                "question_id": i,
                **analysis
            })
            
            # ç»Ÿè®¡éš¾åº¦åˆ†å¸ƒ
            difficulty_level = analysis["éš¾åº¦ç­‰çº§"]
            if difficulty_level in difficulty_distribution:
                difficulty_distribution[difficulty_level] += 1
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = {
            "æ€»é¢˜ç›®æ•°": len(analyses),
            "éš¾åº¦åˆ†å¸ƒ": difficulty_distribution,
            "å¹³å‡ç»¼åˆå¾—åˆ†": np.mean([float(a["ç»¼åˆå¾—åˆ†"]) for a in analyses]),
            "é¢˜ç›®è¯¦æƒ…": analyses
        }
        
        # ä¿å­˜æŠ¥å‘Š
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# é¢˜ç›®éš¾åº¦åˆ†ææŠ¥å‘Š\n\n")
                
                f.write("## æ€»ä½“ç»Ÿè®¡\n")
                f.write(f"- æ€»é¢˜ç›®æ•°: {stats['æ€»é¢˜ç›®æ•°']}\n")
                f.write(f"- å¹³å‡ç»¼åˆå¾—åˆ†: {stats['å¹³å‡ç»¼åˆå¾—åˆ†']:.3f}\n\n")
                
                f.write("## éš¾åº¦åˆ†å¸ƒ\n")
                for level, count in stats['éš¾åº¦åˆ†å¸ƒ'].items():
                    percentage = count / stats['æ€»é¢˜ç›®æ•°'] * 100
                    f.write(f"- {level}: {count} ({percentage:.1f}%)\n")
                
                f.write("\n## è¯¦ç»†åˆ†æ\n\n")
                for analysis in analyses:
                    f.write(f"### é¢˜ç›® {analysis['question_id']}\n")
                    for key, value in analysis.items():
                        if key != "question_id":
                            f.write(f"- {key}: {value}\n")
                    f.write("\n")
        
        print(f"éš¾åº¦åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
        return stats


def get_analyzer_config() -> dict:
    """è·å–åˆ†æå™¨é…ç½®"""
    return {
        "model_name": "BAAI/bge-m3",
        "weights": {
            "similarity": 0.5,
            "length": 0.2,
            "technical_terms": 0.3
        },
        "difficulty_thresholds": {
            "very_easy": 0.2,
            "easy": 0.4,
            "medium": 0.6,
            "hard": 0.8
        }
    }